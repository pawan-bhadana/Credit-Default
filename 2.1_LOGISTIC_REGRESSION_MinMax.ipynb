{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this notebook the independent variables are scaled using MinMaxScaler()\n",
    "- We are focusing on area under ROC curve(Higher the better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Build_Evaluate_Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mBuild_Evaluate_Model\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbem\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Build_Evaluate_Model'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import Build_Evaluate_Model as bem\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### OBTAINING TRAIN AND TEST SET (MINMAXSCALER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=bem.get_xy_traintest(scale=True,scaler='MinMax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASIC LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score_minmax=bem.build_basic_model(X_train,y_train,X_test,y_test,classifier='Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>PARAMS</th>\n",
       "      <th>y_train_prob</th>\n",
       "      <th>y_test_prob</th>\n",
       "      <th>TRAIN SCORE</th>\n",
       "      <th>TEST SCORE</th>\n",
       "      <th>DIFFERENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic</td>\n",
       "      <td>LogisticRegression(max_iter=500, random_state=42)</td>\n",
       "      <td>[0.18021640744759232, 0.15789543226653285, 0.3...</td>\n",
       "      <td>[0.2860633049858224, 0.343463978140098, 0.2603...</td>\n",
       "      <td>0.777212</td>\n",
       "      <td>0.754446</td>\n",
       "      <td>0.022766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MODEL                                             PARAMS  \\\n",
       "0  Basic  LogisticRegression(max_iter=500, random_state=42)   \n",
       "\n",
       "                                        y_train_prob  \\\n",
       "0  [0.18021640744759232, 0.15789543226653285, 0.3...   \n",
       "\n",
       "                                         y_test_prob  TRAIN SCORE  TEST SCORE  \\\n",
       "0  [0.2860633049858224, 0.343463978140098, 0.2603...     0.777212    0.754446   \n",
       "\n",
       "   DIFFERENCE  \n",
       "0    0.022766  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROC AUC Score on basic logistic regression\n",
    "log_score_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASS WEIGHT PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w={0:22,1:77}\n",
    "\n",
    "log_cw=LogisticRegression(max_iter=1000,random_state=42,class_weight=w,penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score_minmax=bem.build_model(X_train,y_train,X_test,y_test,classifier=log_cw,classifier_name='log_cw',score_df=log_score_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>PARAMS</th>\n",
       "      <th>y_train_prob</th>\n",
       "      <th>y_test_prob</th>\n",
       "      <th>TRAIN SCORE</th>\n",
       "      <th>TEST SCORE</th>\n",
       "      <th>DIFFERENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic</td>\n",
       "      <td>LogisticRegression(max_iter=500, random_state=42)</td>\n",
       "      <td>[0.18021640744759232, 0.15789543226653285, 0.3...</td>\n",
       "      <td>[0.2860633049858224, 0.343463978140098, 0.2603...</td>\n",
       "      <td>0.777212</td>\n",
       "      <td>0.754446</td>\n",
       "      <td>0.022766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_cw</td>\n",
       "      <td>LogisticRegression(class_weight={0: 22, 1: 77}...</td>\n",
       "      <td>[0.4365481227588432, 0.3972976900648298, 0.707...</td>\n",
       "      <td>[0.6967057592838225, 0.6559601850205833, 0.544...</td>\n",
       "      <td>0.777627</td>\n",
       "      <td>0.755056</td>\n",
       "      <td>0.022571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MODEL                                             PARAMS  \\\n",
       "0   Basic  LogisticRegression(max_iter=500, random_state=42)   \n",
       "1  log_cw  LogisticRegression(class_weight={0: 22, 1: 77}...   \n",
       "\n",
       "                                        y_train_prob  \\\n",
       "0  [0.18021640744759232, 0.15789543226653285, 0.3...   \n",
       "1  [0.4365481227588432, 0.3972976900648298, 0.707...   \n",
       "\n",
       "                                         y_test_prob  TRAIN SCORE  TEST SCORE  \\\n",
       "0  [0.2860633049858224, 0.343463978140098, 0.2603...     0.777212    0.754446   \n",
       "1  [0.6967057592838225, 0.6559601850205833, 0.544...     0.777627    0.755056   \n",
       "\n",
       "   DIFFERENCE  \n",
       "0    0.022766  \n",
       "1    0.022571  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYPERPARAMETER TUNING FOR LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=[{0:1.0,1:10},{0:1,1:100}, {0:1,1:150},{0:1,1:1},\n",
    "     {0:1.0,1:200},{0:1.0,1:500},{0:100,1:1000},{0:22,1:77},{0:30,1:70},{0:40,1:60},{0:20,1:80},{0:10,1:90}]\n",
    "c_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_grid = {\"class_weight\": w ,'solver':['liblinear'],'penalty':['l1'],'C':c_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7706529891354151 with param: {'C': 0.01, 'class_weight': {0: 100, 1: 1000}, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "log_search_wt=LogisticRegression(max_iter=500,random_state=42)\n",
    "\n",
    "grid = GridSearchCV(log_search_wt,hyperparam_grid,scoring=\"roc_auc\", cv=3, n_jobs=-1)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print(f'Best score: {grid.best_score_} with param: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This above code Best score:{'C': 0.01, 'class_weight': {0: 100, 1: 1000}, 'penalty': 'l1', 'solver': 'liblinear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_best=LogisticRegression(C=0.01, class_weight={0:100, 1:1000}, penalty='l1', solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score_minmax=bem.build_model(X_train,y_train,X_test,y_test,classifier=log_best,classifier_name='log_best',score_df=log_score_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>PARAMS</th>\n",
       "      <th>y_train_prob</th>\n",
       "      <th>y_test_prob</th>\n",
       "      <th>TRAIN SCORE</th>\n",
       "      <th>TEST SCORE</th>\n",
       "      <th>DIFFERENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic</td>\n",
       "      <td>LogisticRegression(max_iter=500, random_state=42)</td>\n",
       "      <td>[0.18021640744759232, 0.15789543226653285, 0.3...</td>\n",
       "      <td>[0.2860633049858224, 0.343463978140098, 0.2603...</td>\n",
       "      <td>0.777212</td>\n",
       "      <td>0.754446</td>\n",
       "      <td>0.022766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_cw</td>\n",
       "      <td>LogisticRegression(class_weight={0: 22, 1: 77}...</td>\n",
       "      <td>[0.4365481227588432, 0.3972976900648298, 0.707...</td>\n",
       "      <td>[0.6967057592838225, 0.6559601850205833, 0.544...</td>\n",
       "      <td>0.777627</td>\n",
       "      <td>0.755056</td>\n",
       "      <td>0.022571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_best</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight={0: 10...</td>\n",
       "      <td>[0.6908074590197232, 0.6535389050694503, 0.870...</td>\n",
       "      <td>[0.8668631950877487, 0.8479692342136933, 0.772...</td>\n",
       "      <td>0.777637</td>\n",
       "      <td>0.755437</td>\n",
       "      <td>0.022199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MODEL                                             PARAMS  \\\n",
       "0     Basic  LogisticRegression(max_iter=500, random_state=42)   \n",
       "1    log_cw  LogisticRegression(class_weight={0: 22, 1: 77}...   \n",
       "2  log_best  LogisticRegression(C=0.01, class_weight={0: 10...   \n",
       "\n",
       "                                        y_train_prob  \\\n",
       "0  [0.18021640744759232, 0.15789543226653285, 0.3...   \n",
       "1  [0.4365481227588432, 0.3972976900648298, 0.707...   \n",
       "2  [0.6908074590197232, 0.6535389050694503, 0.870...   \n",
       "\n",
       "                                         y_test_prob  TRAIN SCORE  TEST SCORE  \\\n",
       "0  [0.2860633049858224, 0.343463978140098, 0.2603...     0.777212    0.754446   \n",
       "1  [0.6967057592838225, 0.6559601850205833, 0.544...     0.777627    0.755056   \n",
       "2  [0.8668631950877487, 0.8479692342136933, 0.772...     0.777637    0.755437   \n",
       "\n",
       "   DIFFERENCE  \n",
       "0    0.022766  \n",
       "1    0.022571  \n",
       "2    0.022199  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHANGING C PARAMETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`c parameter`:Inverse to strength of regularization. Smaller the value higher the regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=[0.001,0.0002,0.0005,0.0001]\n",
    "\n",
    "for c in C:\n",
    "    classifier_name='log_c_'+str(c)\n",
    "    log=LogisticRegression(C=c, class_weight={0:30, 1:70}, penalty='l1', solver='liblinear')\n",
    "    log_score_minmax=bem.build_model(X_train,y_train,X_test,y_test,classifier=log,classifier_name=classifier_name,score_df=log_score_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score_minmax=bem.build_ensemble(X_train,y_train,X_test,y_test,classifier_name='log',score_df=log_score_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>PARAMS</th>\n",
       "      <th>y_train_prob</th>\n",
       "      <th>y_test_prob</th>\n",
       "      <th>TRAIN SCORE</th>\n",
       "      <th>TEST SCORE</th>\n",
       "      <th>DIFFERENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>log_c_0.0001</td>\n",
       "      <td>LogisticRegression(C=0.0001, class_weight={0: ...</td>\n",
       "      <td>[0.40931312696431155, 0.39662822150709814, 0.5...</td>\n",
       "      <td>[0.41530278411762234, 0.5162386017098676, 0.47...</td>\n",
       "      <td>0.768658</td>\n",
       "      <td>0.756304</td>\n",
       "      <td>0.012355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log_c_0.0002</td>\n",
       "      <td>LogisticRegression(C=0.0002, class_weight={0: ...</td>\n",
       "      <td>[0.3649483120425892, 0.3498199553402743, 0.501...</td>\n",
       "      <td>[0.37633244719602715, 0.5409804973485722, 0.45...</td>\n",
       "      <td>0.772187</td>\n",
       "      <td>0.755137</td>\n",
       "      <td>0.017050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>log_c_0.0005</td>\n",
       "      <td>LogisticRegression(C=0.0005, class_weight={0: ...</td>\n",
       "      <td>[0.3361783533505103, 0.32001903654777947, 0.50...</td>\n",
       "      <td>[0.31913030685936794, 0.5498732836677761, 0.44...</td>\n",
       "      <td>0.773981</td>\n",
       "      <td>0.754599</td>\n",
       "      <td>0.019382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>log_ensemble</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.3933712541285023, 0.36897402123730494, 0.56...</td>\n",
       "      <td>[0.46506113236011887, 0.5719203015698848, 0.48...</td>\n",
       "      <td>0.776580</td>\n",
       "      <td>0.756262</td>\n",
       "      <td>0.020318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log_c_0.001</td>\n",
       "      <td>LogisticRegression(C=0.001, class_weight={0: 3...</td>\n",
       "      <td>[0.3355869973159465, 0.3076189078651693, 0.508...</td>\n",
       "      <td>[0.2950301289904209, 0.5489563308886034, 0.448...</td>\n",
       "      <td>0.775479</td>\n",
       "      <td>0.754911</td>\n",
       "      <td>0.020567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_best</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight={0: 10...</td>\n",
       "      <td>[0.6908074590197232, 0.6535389050694503, 0.870...</td>\n",
       "      <td>[0.8668631950877487, 0.8479692342136933, 0.772...</td>\n",
       "      <td>0.777637</td>\n",
       "      <td>0.755437</td>\n",
       "      <td>0.022199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_cw</td>\n",
       "      <td>LogisticRegression(class_weight={0: 22, 1: 77}...</td>\n",
       "      <td>[0.4365481227588432, 0.3972976900648298, 0.707...</td>\n",
       "      <td>[0.6967057592838225, 0.6559601850205833, 0.544...</td>\n",
       "      <td>0.777627</td>\n",
       "      <td>0.755056</td>\n",
       "      <td>0.022571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic</td>\n",
       "      <td>LogisticRegression(max_iter=500, random_state=42)</td>\n",
       "      <td>[0.18021640744759232, 0.15789543226653285, 0.3...</td>\n",
       "      <td>[0.2860633049858224, 0.343463978140098, 0.2603...</td>\n",
       "      <td>0.777212</td>\n",
       "      <td>0.754446</td>\n",
       "      <td>0.022766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MODEL                                             PARAMS  \\\n",
       "6  log_c_0.0001  LogisticRegression(C=0.0001, class_weight={0: ...   \n",
       "4  log_c_0.0002  LogisticRegression(C=0.0002, class_weight={0: ...   \n",
       "5  log_c_0.0005  LogisticRegression(C=0.0005, class_weight={0: ...   \n",
       "7  log_ensemble                                                NaN   \n",
       "3   log_c_0.001  LogisticRegression(C=0.001, class_weight={0: 3...   \n",
       "2      log_best  LogisticRegression(C=0.01, class_weight={0: 10...   \n",
       "1        log_cw  LogisticRegression(class_weight={0: 22, 1: 77}...   \n",
       "0         Basic  LogisticRegression(max_iter=500, random_state=42)   \n",
       "\n",
       "                                        y_train_prob  \\\n",
       "6  [0.40931312696431155, 0.39662822150709814, 0.5...   \n",
       "4  [0.3649483120425892, 0.3498199553402743, 0.501...   \n",
       "5  [0.3361783533505103, 0.32001903654777947, 0.50...   \n",
       "7  [0.3933712541285023, 0.36897402123730494, 0.56...   \n",
       "3  [0.3355869973159465, 0.3076189078651693, 0.508...   \n",
       "2  [0.6908074590197232, 0.6535389050694503, 0.870...   \n",
       "1  [0.4365481227588432, 0.3972976900648298, 0.707...   \n",
       "0  [0.18021640744759232, 0.15789543226653285, 0.3...   \n",
       "\n",
       "                                         y_test_prob  TRAIN SCORE  TEST SCORE  \\\n",
       "6  [0.41530278411762234, 0.5162386017098676, 0.47...     0.768658    0.756304   \n",
       "4  [0.37633244719602715, 0.5409804973485722, 0.45...     0.772187    0.755137   \n",
       "5  [0.31913030685936794, 0.5498732836677761, 0.44...     0.773981    0.754599   \n",
       "7  [0.46506113236011887, 0.5719203015698848, 0.48...     0.776580    0.756262   \n",
       "3  [0.2950301289904209, 0.5489563308886034, 0.448...     0.775479    0.754911   \n",
       "2  [0.8668631950877487, 0.8479692342136933, 0.772...     0.777637    0.755437   \n",
       "1  [0.6967057592838225, 0.6559601850205833, 0.544...     0.777627    0.755056   \n",
       "0  [0.2860633049858224, 0.343463978140098, 0.2603...     0.777212    0.754446   \n",
       "\n",
       "   DIFFERENCE  \n",
       "6    0.012355  \n",
       "4    0.017050  \n",
       "5    0.019382  \n",
       "7    0.020318  \n",
       "3    0.020567  \n",
       "2    0.022199  \n",
       "1    0.022571  \n",
       "0    0.022766  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score_minmax.sort_values(by='DIFFERENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MODEL                                                log_c_0.0001\n",
       "PARAMS          LogisticRegression(C=0.0001, class_weight={0: ...\n",
       "y_train_prob    [0.40931312696431155, 0.39662822150709814, 0.5...\n",
       "y_test_prob     [0.41530278411762234, 0.5162386017098676, 0.47...\n",
       "TRAIN SCORE                                              0.768658\n",
       "TEST SCORE                                               0.756304\n",
       "DIFFERENCE                                              0.0123545\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score_minmax.sort_values(by='DIFFERENCE').iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
